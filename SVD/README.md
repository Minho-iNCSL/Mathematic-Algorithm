# SVD (Singular Value Decomposition) ğŸ“’

![image](https://user-images.githubusercontent.com/60316325/231943786-a65eba04-4671-40ba-be0a-e2e7ba9b82ee.png)

* It is one of  the most useful matrix decompositions.
* It is used for finding a solution of an over-determined set of equations.<br>
(ì¦‰, ë°©ì •ì‹ì˜ ê°œìˆ˜ê°€ ë¯¸ì§€ìˆ˜ì˜ ê°œìˆ˜ë³´ë‹¤ ë” ë§ì€ ê²½ìš° Over-determinded ë˜ì—ˆë‹¤ê³  í•œë‹¤.)
* Let A be an $m\times n$ matrix with $m\ge n$.
    * A may be factored as $A = UDV^T$ <br>
        \- $U$ is an $m\times m$ orthogonal(ì§êµ) matrix.<br>
        \- $D$ is an $m\times n$ matrix. (non-diagonal terms are all zeros, ëŒ€ê°ì„±ë¶„ ë¹¼ê³ ëŠ” ë‹¤ 0.)<br>
        \- $V$ is an $n\times n$ orthogonal matrix.<br>
    * The fact that U has orthogonal columns means that $U^TU = I_{m\times m}$. 
    * $U$ëŠ”, $AA^T$ë¥¼ ê³ ìœ ê°’ë¶„í•´í•˜ì—¬ ì–»ì–´ì§„ ì§êµí–‰ë ¬ë¡œ, $U$ì˜ ì—´ë²¡í„°ë¥¼ $A$ì˜ Left Singular Vector ë¼ê³  ë¶€ë¥¸ë‹¤. 
    * $V$ëŠ”, $A^TA$ë¥¼ ê³ ìœ ê°’ë¶„í•´í•˜ì—¬ ì–»ì–´ì§„ ì§êµí–‰ë ¬ë¡œ, $V$ì˜ ì—´ë²¡í„°ë¥¼ $A$ì˜ Right Singular Vector ë¼ê³  ë¶€ë¥¸ë‹¤. 
    * $D$ëŠ” Uì™€ Vë¥¼ ê³ ìœ ê°’ë¶„í•´í•˜ì—¬ ë‚˜ì˜¤ëŠ” ê³ ìœ ê°’(eigenvalue)ë“¤ì˜ Square rootë¥¼ ëŒ€ê°ì›ì†Œë¡œ í•˜ëŠ” ì§ì‚¬ê° ëŒ€ê°í–‰ë ¬.
    * $D$ì˜ ëŒ€ê°ì›ì†Œë“¤ì„ Aì˜ íŠ¹ì´ê°’(Singular Value)ì´ë¼ ë¶€ë¥¸ë‹¤. (Singular Value $\ge$ 0) <br>

---

* When an equation looks like $X\mathbf{p} = \mathbf{y}$, we can simply use the pseudoinverse. <br>
( Refer to : Least Squares Method )
* What about an equation that looks like $X\mathbf{p} = 0$ ? <br>
  * $\mathbf{0}$ is not of interest, and a non-zero solution should be found.<br>
  * The pseudoinverse cannot be used to find $\mathbf{p}$. <br>
* For instance, we somtimes need to find a line using the model, $ax+by+c = 0$ instead of the model $y=ax+b$.
  * We have to find $\mathbf{p}$ for $X\mathbf{p} = 0$.
  
$$X =
\begin{bmatrix} 
x_1&y_1&1 \\ 
x_2&y_2&1 \\ 
\vdots&\vdots&\vdots \\ 
x_N&y_N&1 \end{bmatrix}, \quad
\mathbf{p} = 
\begin{bmatrix} 
a \\
b \\
c \\
\end{bmatrix}
$$

**In this case, we have to use the "sigular value decomposition (SVD)"**

---

* For $X\mathbf{p} = 0$, and $\mathbf{p}$ is a solution, Our goal is to find the $\mathbf{p}$ that minimizes $\parallel X\mathbf{p}\parallel$ subject to $\parallel \mathbf{p}\parallel = 1$.

  * Let $X$ be factorized into $UDV^T$ by SVD.
  * $\parallel X\mathbf{p}\parallel = \parallel UDV^T\mathbf{p}\parallel = \parallel DV^T\mathbf{p}\parallel$ <br>
  (Because, $U$ is an orthogonal(ì§êµ) Matrix, it does not change the norm) <br>
  * $\parallel V^T\mathbf{p}\parallel = \parallel \mathbf{p}\parallel$ <br>
  (Because, $V$ is also an orthogonal matrix.)<br>
  * Let $V^T\mathbf{p} = \mathbf{K}$.
  
* If we let $V^T\mathbf{p} = \mathbf{K}$, then $\parallel X\mathbf{p}\parallel = \parallel D\mathbf{K}\parallel$ and $\parallel \mathbf{p}\parallel = \parallel \mathbf{K}\parallel$.
* Our goal can be changed like... **find $\mathbf{K}$ that minimizes $\parallel D\mathbf{K}\parallel$ subject to $\parallel \mathbf{K}\parallel = 1$**.

---

* Because our goal is to find $\mathbf{K}$ that minimizes $\parallel D\mathbf{K}\parallel$ subject to $\parallel \mathbf{K}\parallel = 1$.
  * $D$ is a diagonal matrix with its diagonal entries in descending order (ë‚´ë¦¼ì°¨ìˆœ). <br>
  ($D$ í–‰ë ¬ì€ ëŒ€ê°ì„ ìƒì— ìœ„ì¹˜í•œ ì›ì†Œë“¤ì€ Xì˜ íŠ¹ì´ê°’ë“¤ë¡œ ì´ë£¨ì–´ì ¸ìˆë‹¤.)
  * It follows that the solution to this problem is $\mathbf{K} = [0, 0, ..., 1]^T$.
  * $\mathbf{K} = V^T\mathbf{p} \Rightarrow \mathbf{p} = V\mathbf{K}$ (Because $V^{-1} = V^T$ when $V$ is an orthogonal matrix)
  * Because $\mathbf{p} = V\mathbf{K}$ and $\mathbf{K} = [0, 0, ..., 1]^T$, $\mathbf{p}$ is simply the last column of $V$.
  
    * ì¦‰, $Ax = 0$ì˜ í˜•íƒœì¼ ë•Œ, 
    * íŠ¹ì´ê°’ì´ ëª¨ë‘ ì–‘ìˆ˜ì¸ ê²½ìš°, ìµœì†Œ íŠ¹ì´ê°’ì— í•´ë‹¹í•˜ëŠ” ê·¼ì‚¬ í•´, ì¦‰ $x$ëŠ” $V$ë²¡í„°ì˜ ê°€ì¥ ìš°ì¸¡ ì—´ë²¡í„°ê°€ í•´ê°€ ëœë‹¤. <br>(Aì˜ ìµœì†Œ íŠ¹ì´ê°’ì— ëŒ€ì‘í•˜ëŠ” right singular verctor)
    * ì›ë˜ëŠ” íŠ¹ì´ê°’ë“¤ ì¤‘ 0 ì´ ì¡´ì¬í•˜ë©´, ê·¸ íŠ¹ì´ê°’ì— í•´ë‹¹í•˜ëŠ” $V$ì˜ ì—´ë²¡í„°ê°€ ëª¨ë‘ í•´ê°€ ëœë‹¤.
  
* In Conclusion..
  * Objective(ëª©ì ) : Given a matrix $X$ with at least as many rows as columns, find $\mathbf{p}$ that minimizes $\parallel X\mathbf{p}\parallel$ subject to $\parallel \mathbf{p}\parallel = 1$. 
  * Solution(ë°©ì•ˆ, í•´) : $\mathbf{p}$ is the last column of $V$, where $UDV^T$ is the SVD of $X$.
  
---
  
![image](https://user-images.githubusercontent.com/60316325/232276716-c9410880-ef28-46f3-afa1-9e91977b1423.png)

